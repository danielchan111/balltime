{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1f17066a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f17066a",
        "outputId": "e80adc6e-c200-4292-dc96-e379fd4f491d",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'balltime'...\n",
            "remote: Enumerating objects: 85, done.\u001b[K\n",
            "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
            "remote: Total 85 (delta 13), reused 83 (delta 11), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (85/85), 86.59 KiB | 6.66 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n",
            "/content/balltime\n",
            "CWD: /content/balltime\n",
            "Files here: ['.git', 'video_objects.py', 'video_true_labels.csv', 'notebooks', '.DS_Store', 'label_videos.py', '__pycache__', 'models', 'requirements.txt']\n"
          ]
        }
      ],
      "source": [
        "!rm -rf balltime\n",
        "!git clone https://github.com/danielchan111/balltime.git\n",
        "%cd balltime\n",
        "\n",
        "from pathlib import Path\n",
        "print(\"CWD:\", Path.cwd())\n",
        "print(\"Files here:\", [p.name for p in Path('.').iterdir()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dca182af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dca182af",
        "outputId": "eafea24a-eeba-4aa4-87df-bc04b9cef3d2",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/facebookresearch/pytorchvideo (from -r requirements.txt (line 23))\n",
            "  Cloning https://github.com/facebookresearch/pytorchvideo to /tmp/pip-req-build-ubicd3cj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/pytorchvideo /tmp/pip-req-build-ubicd3cj\n",
            "  Resolved https://github.com/facebookresearch/pytorchvideo to commit 0f9a5e102e4d84972b829fd30e3c3f78c7c7fd1a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: scipy==1.11.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn==1.3.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (0.24.0+cu126)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (8.3.237)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (4.57.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (4.11.0.86)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (11.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (2.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (0.13.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (4.67.1)\n",
            "Requirement already satisfied: supervision in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (0.27.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (0.6.7)\n",
            "Requirement already satisfied: norfair in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (2.3.0)\n",
            "Requirement already satisfied: filterpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (1.4.5)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 19)) (5.2.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 20)) (2.12.3)\n",
            "Requirement already satisfied: pydantic-settings in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 21)) (2.12.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.2->-r requirements.txt (line 3)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.2->-r requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (3.5.0)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics->-r requirements.txt (line 7)) (3.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics->-r requirements.txt (line 7)) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics->-r requirements.txt (line 7)) (2.32.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics->-r requirements.txt (line 7)) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics->-r requirements.txt (line 7)) (1.31.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.18 in /usr/local/lib/python3.12/dist-packages (from ultralytics->-r requirements.txt (line 7)) (2.0.18)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 8)) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 8)) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 8)) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 8)) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 11)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 11)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 11)) (2025.2)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from supervision->-r requirements.txt (line 14)) (0.7.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->-r requirements.txt (line 16)) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->-r requirements.txt (line 16)) (0.9.0)\n",
            "Requirement already satisfied: rich<15.0.0,>=9.10.0 in /usr/local/lib/python3.12/dist-packages (from norfair->-r requirements.txt (line 17)) (13.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown->-r requirements.txt (line 19)) (4.13.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r requirements.txt (line 20)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r requirements.txt (line 20)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r requirements.txt (line 20)) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings->-r requirements.txt (line 21)) (1.2.1)\n",
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.12/dist-packages (from pytorchvideo==0.1.5->-r requirements.txt (line 23)) (0.1.5.post20221221)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.12/dist-packages (from pytorchvideo==0.1.5->-r requirements.txt (line 23)) (16.0.1)\n",
            "Requirement already satisfied: parameterized in /usr/local/lib/python3.12/dist-packages (from pytorchvideo==0.1.5->-r requirements.txt (line 23)) (0.9.0)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.12/dist-packages (from pytorchvideo==0.1.5->-r requirements.txt (line 23)) (0.1.10)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements.txt (line 8)) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 7)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 7)) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 7)) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 7)) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 11)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 7)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 7)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 7)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 7)) (2025.11.12)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=9.10.0->norfair->-r requirements.txt (line 17)) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=9.10.0->norfair->-r requirements.txt (line 17)) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->-r requirements.txt (line 16)) (1.1.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown->-r requirements.txt (line 19)) (2.8)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from fvcore->pytorchvideo==0.1.5->-r requirements.txt (line 23)) (0.1.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.12/dist-packages (from fvcore->pytorchvideo==0.1.5->-r requirements.txt (line 23)) (3.2.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from fvcore->pytorchvideo==0.1.5->-r requirements.txt (line 23)) (0.9.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from iopath->pytorchvideo==0.1.5->-r requirements.txt (line 23)) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements.txt (line 5)) (3.0.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 19)) (1.7.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=9.10.0->norfair->-r requirements.txt (line 17)) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0f136162",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f136162",
        "outputId": "65ccfe7c-0719-4aee-b50b-482a6848ecfd",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[32mINFO: ML Manager initialized on device: cuda:0\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO:ml_manager:ML Manager initialized on device: cuda:0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: Using default weights configuration\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO:ml_manager:Using default weights configuration\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: Initializing deep learning models...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO:ml_manager:Initializing deep learning models...\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: Missing model weights detected: ['ball_detection', 'action_detection', 'court_detection', 'game_state']\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO:ml_manager:Missing model weights detected: ['ball_detection', 'action_detection', 'court_detection', 'game_state']\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: Downloading missing weights from Google Drive...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO:ml_manager:Downloading missing weights from Google Drive...\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: Downloading complete weights ZIP file from Google Drive...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO:ml_manager:Downloading complete weights ZIP file from Google Drive...\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: Downloading from Google Drive (ID: 1__zkTmGwZo2z0EgbJvC14I_3kOpgQx3o) to /content/balltime/weights/all_weights.zip\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO:ml_manager:Downloading from Google Drive (ID: 1__zkTmGwZo2z0EgbJvC14I_3kOpgQx3o) to /content/balltime/weights/all_weights.zip\u001b[0m\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1__zkTmGwZo2z0EgbJvC14I_3kOpgQx3o\n",
            "From (redirected): https://drive.google.com/uc?id=1__zkTmGwZo2z0EgbJvC14I_3kOpgQx3o&confirm=t&uuid=e5830e15-d610-4e9b-99c9-c934219274f9\n",
            "To: /content/balltime/weights/all_weights.zip\n",
            "100%|██████████| 401M/401M [00:07<00:00, 54.1MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: Successfully downloaded to /content/balltime/weights/all_weights.zip\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[32mINFO:ml_manager:Successfully downloaded to /content/balltime/weights/all_weights.zip\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: Extracting weights to /content/balltime/weights\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO:ml_manager:Extracting weights to /content/balltime/weights\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: ZIP file extracted and removed\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO:ml_manager:ZIP file extracted and removed\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mSUCCESS: Successfully extracted all 4 models\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mSUCCESS:ml_manager:Successfully extracted all 4 models\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mSUCCESS: Successfully downloaded all model weights\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mSUCCESS:ml_manager:Successfully downloaded all model weights\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: Initializing ActionDetector with model: /content/balltime/weights/action/weights/best.pt\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO:ml_manager:Initializing ActionDetector with model: /content/balltime/weights/action/weights/best.pt\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: Loading YOLO model from: /content/balltime/weights/action/weights/best.pt\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO:ml_manager:Loading YOLO model from: /content/balltime/weights/action/weights/best.pt\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: Moving YOLO model to device: cuda:0\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO:ml_manager:Moving YOLO model to device: cuda:0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mSUCCESS: Action detection model loaded: /content/balltime/weights/action/weights/best.pt\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mSUCCESS:ml_manager:Action detection model loaded: /content/balltime/weights/action/weights/best.pt\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: Initializing BallDetector with model: /content/balltime/weights/ball/weights/best.pt\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO:ml_manager:Initializing BallDetector with model: /content/balltime/weights/ball/weights/best.pt\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: Loading YOLO model from: /content/balltime/weights/ball/weights/best.pt\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO:ml_manager:Loading YOLO model from: /content/balltime/weights/ball/weights/best.pt\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: Moving YOLO model to device: cuda:0\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO:ml_manager:Moving YOLO model to device: cuda:0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mSUCCESS: Ball segmentation model loaded: /content/balltime/weights/ball/weights/best.pt\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mSUCCESS:ml_manager:Ball segmentation model loaded: /content/balltime/weights/ball/weights/best.pt\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: Initializing CourtSegmentation with model: /content/balltime/weights/court/weights/best.pt\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO:ml_manager:Initializing CourtSegmentation with model: /content/balltime/weights/court/weights/best.pt\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: Loading YOLO model from: /content/balltime/weights/court/weights/best.pt\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO:ml_manager:Loading YOLO model from: /content/balltime/weights/court/weights/best.pt\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: Moving YOLO model to device: cuda:0\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO:ml_manager:Moving YOLO model to device: cuda:0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mSUCCESS: Court segmentation model loaded: /content/balltime/weights/court/weights/best.pt\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mSUCCESS:ml_manager:Court segmentation model loaded: /content/balltime/weights/court/weights/best.pt\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: Initializing PlayerModule with model: yolo11n-pose.pt\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO:ml_manager:Initializing PlayerModule with model: yolo11n-pose.pt\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: Loading YOLO model from: yolo11n-pose.pt\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO:ml_manager:Loading YOLO model from: yolo11n-pose.pt\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-pose.pt to 'yolo11n-pose.pt': 100% ━━━━━━━━━━━━ 6.0MB 237.1MB/s 0.0s\n",
            "\u001b[32mINFO: Moving YOLO model to device: cuda:0\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO:ml_manager:Moving YOLO model to device: cuda:0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mSUCCESS: Default YOLO pose estimation model loaded for player keypoint detection\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mSUCCESS:ml_manager:Default YOLO pose estimation model loaded for player keypoint detection\u001b[0m\n",
            "WARNING:root:You are using a scalar distance function. If you want to speed up the tracking process please consider using a vectorized distance function such as ['iou', 'iou_opt', 'braycurtis', 'canberra', 'chebyshev', 'cityblock', 'correlation', 'cosine', 'dice', 'euclidean', 'hamming', 'jaccard', 'jensenshannon', 'kulczynski1', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule'].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mSUCCESS: Tracking module initialized successfully\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mSUCCESS:ml_manager:Tracking module initialized successfully\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: Initializing GameStatusClassifier with model: /content/balltime/weights/game_state\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO:ml_manager:Initializing GameStatusClassifier with model: /content/balltime/weights/game_state\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Failed to load game state classification model: Failed to load VideoMAE model: Error(s) in loading state_dict for Linear:\n",
            "\tsize mismatch for bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([2]).\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR:ml_manager:Failed to load game state classification model: Failed to load VideoMAE model: Error(s) in loading state_dict for Linear:\n",
            "\tsize mismatch for bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([2]).\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mSUCCESS: Visualization module initialized successfully\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mSUCCESS:ml_manager:Visualization module initialized successfully\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mSUCCESS: All models initialized successfully!\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mSUCCESS:ml_manager:All models initialized successfully!\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ MLManager imported & initialized\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
        "\n",
        "if str(MODELS_DIR) not in sys.path:\n",
        "    sys.path.append(str(MODELS_DIR))\n",
        "\n",
        "from volleyball_ml import MLManager\n",
        "\n",
        "manager = MLManager(device=\"cuda:0\")  # or \"cuda\" if you enabled GPU\n",
        "print(\"✅ MLManager imported & initialized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4361bf5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4361bf5a",
        "outputId": "9bc4aae3-797f-4bf5-e10a-fa4e99189ced"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on Colab. Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "✅ Videos found at /content/drive/MyDrive/videos\n"
          ]
        }
      ],
      "source": [
        "# Auto-detect Colab and mount Google Drive for videos\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "IS_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IS_COLAB:\n",
        "    print(\"Running on Colab. Mounting Google Drive...\")\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "    # Point to videos folder on Drive\n",
        "    DRIVE_VIDEOS_PATH = Path('/content/drive/MyDrive/videos')\n",
        "    if DRIVE_VIDEOS_PATH.exists():\n",
        "        print(f\"✅ Videos found at {DRIVE_VIDEOS_PATH}\")\n",
        "    else:\n",
        "        print(f\"⚠️  {DRIVE_VIDEOS_PATH} not found. Ensure videos are in MyDrive/videos/\")\n",
        "else:\n",
        "    print(\"Running locally. Using local balltime/videos folder.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7393e69",
      "metadata": {
        "id": "a7393e69",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "# Import video_objects from src\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "SRC_DIR = PROJECT_ROOT / \"src\"\n",
        "\n",
        "if str(SRC_DIR) not in sys.path:\n",
        "    sys.path.insert(0, str(SRC_DIR))\n",
        "\n",
        "from video_objects import (\n",
        "    VideoObject,\n",
        "    VideoDetectionTensor,\n",
        "    videos_to_objects,\n",
        "    train_test_split_videos,\n",
        "    build_binary_labels_for_video,\n",
        "    write_video_binary_labels_row,\n",
        "    build_and_write_video_labels_csv_row,\n",
        ")\n",
        "\n",
        "print(\"✅ video_objects imported from src/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "17d291ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17d291ed",
        "outputId": "88407a5b-276f-4a4f-c6c0-1daa8a172e39",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using VIDEOS_DIR=/content/drive/MyDrive/videos\n",
            "Found 21 video files: ['BUNCGB1.mp4', 'BUNCB2.mp4', 'BUNCB1.mp4', 'BUNCGB2.mp4', 'BUNCGB22.mp4', 'BUNCGB21.mp4', 'BUNCB22.mp4', 'BUNCB21.mp4', 'BHPU2.mp4', 'BHPU1.mp4', 'UNCC1.mp4', 'UNCC2.mp4', 'UNCW1.mp4', 'UNCW2.mp4', 'NCSU1.mp4', 'NCSU2.mp4', 'NCSU3.mp4', 'UNCGB1.mp4', 'UNCGB2.mp4', 'APPB1.mp4', 'APPB2.mp4']\n",
            "Copying videos from Drive to local /tmp (fast)...\n",
            "  Copying BUNCGB1.mp4...\n",
            "  Copying BUNCB2.mp4...\n",
            "  Copying BUNCB1.mp4...\n",
            "  Copying BUNCGB2.mp4...\n",
            "  Copying BUNCGB22.mp4...\n",
            "  Copying BUNCGB21.mp4...\n",
            "  Copying BUNCB22.mp4...\n",
            "  Copying BUNCB21.mp4...\n",
            "  Copying BHPU2.mp4...\n",
            "  Copying BHPU1.mp4...\n",
            "  Copying UNCC1.mp4...\n",
            "  Copying UNCC2.mp4...\n",
            "  Copying UNCW1.mp4...\n",
            "  Copying UNCW2.mp4...\n",
            "  Copying NCSU1.mp4...\n",
            "  Copying NCSU2.mp4...\n",
            "  Copying NCSU3.mp4...\n",
            "  Copying UNCGB1.mp4...\n",
            "  Copying UNCGB2.mp4...\n",
            "  Copying APPB1.mp4...\n",
            "  Copying APPB2.mp4...\n",
            "✅ Videos copied to /tmp/balltime_videos\n",
            "Video objects created: 21\n",
            "Train: 5 | Val: 1 | Test: 2\n",
            "Train videos: ['UNCW2.mp4', 'BHPU2.mp4', 'APPB1.mp4', 'BUNCGB1.mp4', 'BUNCB22.mp4']\n"
          ]
        }
      ],
      "source": [
        "# Minimal imports only (assumes prior cells ran and installed versions)\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Determine videos directory based on environment\n",
        "if IS_COLAB:\n",
        "    VIDEOS_DIR = DRIVE_VIDEOS_PATH  # From Drive mount cell\n",
        "else:\n",
        "    # Local: use repo videos folder\n",
        "    try:\n",
        "        PROJECT_ROOT\n",
        "    except NameError:\n",
        "        PROJECT_ROOT = Path.cwd()\n",
        "    VIDEOS_DIR = (PROJECT_ROOT / \"videos\").resolve()\n",
        "\n",
        "VIDEOS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Debug: list video files found\n",
        "exts = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}\n",
        "video_files = [p for p in VIDEOS_DIR.iterdir() if p.suffix.lower() in exts]\n",
        "print(f\"Using VIDEOS_DIR={VIDEOS_DIR}\")\n",
        "print(f\"Found {len(video_files)} video files: {[p.name for p in video_files]}\" if video_files else \"No video files detected in videos directory.\")\n",
        "\n",
        "# Inference parameters\n",
        "BATCH_SIZE = 64\n",
        "SAMPLE_RATE = 4\n",
        "CONF_THRESHOLD = 0.35\n",
        "FP16 = True\n",
        "TOP_HALF_ONLY = True  # run detection on top half to save compute\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "if IS_COLAB:\n",
        "    LOCAL_VIDEOS_DIR = Path(\"/tmp/balltime_videos\")\n",
        "    LOCAL_VIDEOS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "    print(\"Copying videos from Drive to local /tmp (fast)...\")\n",
        "    for video_file in DRIVE_VIDEOS_PATH.iterdir():\n",
        "        if video_file.suffix.lower() in {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}:\n",
        "            dest = LOCAL_VIDEOS_DIR / video_file.name\n",
        "            print(f\"  Copying {video_file.name}...\")\n",
        "            shutil.copy2(video_file, dest)\n",
        "\n",
        "    VIDEOS_DIR = LOCAL_VIDEOS_DIR\n",
        "    print(f\"✅ Videos copied to {VIDEOS_DIR}\")\n",
        "else:\n",
        "    # Local: use balltime/videos as-is\n",
        "    pass\n",
        "\n",
        "\n",
        "# Build video object list from in-notebook definitions\n",
        "video_objs = videos_to_objects(VIDEOS_DIR)\n",
        "print(f\"Video objects created: {len(video_objs)}\")\n",
        "\n",
        "import random\n",
        "\n",
        "# Fixed split: 5 train, 1 val, 2 test; randomly selected\n",
        "REQ_TRAIN, REQ_VAL, REQ_TEST = 5, 1, 2\n",
        "TOTAL_REQ = REQ_TRAIN + REQ_VAL + REQ_TEST\n",
        "\n",
        "if len(video_objs) < TOTAL_REQ:\n",
        "    print(f\"Need at least {TOTAL_REQ} videos; found {len(video_objs)}. Add more videos.\")\n",
        "    train_videos, val_videos, test_videos = [], [], []\n",
        "else:\n",
        "    # Shuffle and split randomly\n",
        "    random.seed(42)  # For reproducibility; change or remove for different splits each run\n",
        "    shuffled = random.sample(video_objs, len(video_objs))\n",
        "\n",
        "    train_videos = shuffled[:REQ_TRAIN]\n",
        "    val_videos = shuffled[REQ_TRAIN:REQ_TRAIN + REQ_VAL]\n",
        "    test_videos = shuffled[REQ_TRAIN + REQ_VAL:REQ_TRAIN + REQ_VAL + REQ_TEST]\n",
        "    extras = shuffled[TOTAL_REQ:]\n",
        "\n",
        "    print(f\"Train: {len(train_videos)} | Val: {len(val_videos)} | Test: {len(test_videos)}\")\n",
        "    print(f\"Train videos: {[v.video_path.name for v in train_videos]}\")\n",
        "\n",
        "# Access the YOLO model from MLManager (initialized earlier)\n",
        "model = manager.ball_detector.yolo_module.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1210d397",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1210d397",
        "outputId": "965cf91d-8cce-4921-b4d2-2fdf9cb5a037",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building tensors for training set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing UNCW2.mp4:  99%|█████████▉| 8768/8841 [14:37<00:07,  9.99it/s]\n",
            "Processing BHPU2.mp4: 100%|██████████| 10425/10425 [18:08<00:00,  9.58it/s]\n",
            "Processing APPB1.mp4: 100%|██████████| 7605/7605 [11:40<00:00, 10.85it/s]\n",
            "Processing BUNCGB1.mp4: 100%|██████████| 8288/8288 [13:19<00:00, 10.36it/s]\n",
            "Processing BUNCB22.mp4: 100%|██████████| 8124/8124 [12:54<00:00, 10.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building tensors for validation set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing UNCC2.mp4: 100%|█████████▉| 13248/13286 [21:43<00:03, 10.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building tensors for test set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing BHPU1.mp4: 100%|██████████| 10913/10913 [18:44<00:00,  9.70it/s]\n",
            "Processing BUNCGB22.mp4: 100%|██████████| 8810/8810 [14:48<00:00,  9.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote CSV: /content/balltime/tensor_index.csv\n",
            "All tensors built and CSV written.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def process_video_to_tensor(video_obj: VideoObject,\n",
        "                            batch_size: int = BATCH_SIZE,\n",
        "                            sample_rate: int = SAMPLE_RATE,\n",
        "                            conf_threshold: float = CONF_THRESHOLD,\n",
        "                            fp16: bool = FP16,\n",
        "                            top_half_only: bool = TOP_HALF_ONLY) -> VideoDetectionTensor:\n",
        "    \"\"\"Run batched, optional FP16 inference with frame skipping and store confidences tensor.\n",
        "    Optionally crops frames to top half before inference to reduce pixels processed.\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(str(video_obj.video_path))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    fps = float(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    sampled_count = (total_frames + sample_rate - 1) // sample_rate\n",
        "    confidences = np.zeros(sampled_count, dtype=np.float16 if fp16 else np.float32)\n",
        "\n",
        "    frames_batch = []\n",
        "    batch_indices = []\n",
        "    out_idx = 0\n",
        "\n",
        "    pbar = tqdm(total=sampled_count, desc=f\"Processing {video_obj.video_path.name}\")\n",
        "\n",
        "    for frame_idx in range(0, total_frames, sample_rate):\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
        "        ok, frame = cap.read()\n",
        "        if not ok:\n",
        "            break\n",
        "\n",
        "        if top_half_only:\n",
        "            h = frame.shape[0]\n",
        "            frame = frame[: h // 2, :, :]\n",
        "\n",
        "        frames_batch.append(frame)\n",
        "        batch_indices.append(out_idx)\n",
        "        out_idx += 1\n",
        "\n",
        "        # Run when batch is full or at end\n",
        "        at_end = (frame_idx + sample_rate >= total_frames)\n",
        "        if len(frames_batch) == batch_size or at_end:\n",
        "            # Ultralytics YOLO inference; half=True for FP16\n",
        "            results = model(frames_batch, conf=conf_threshold, verbose=False, half=fp16)\n",
        "\n",
        "            # Store confidences (0 when no detection)\n",
        "            for i, res in enumerate(results):\n",
        "                idx = batch_indices[i]\n",
        "                if hasattr(res, 'boxes') and res.boxes is not None and len(res.boxes) > 0:\n",
        "                    best = res.boxes.conf.argmax()\n",
        "                    confidences[idx] = float(res.boxes.conf[best])\n",
        "                else:\n",
        "                    confidences[idx] = 0.0\n",
        "\n",
        "            pbar.update(len(frames_batch))\n",
        "            frames_batch.clear()\n",
        "            batch_indices.clear()\n",
        "\n",
        "    cap.release()\n",
        "    pbar.close()\n",
        "\n",
        "    tensor = VideoDetectionTensor(\n",
        "        video_path=video_obj.video_path,\n",
        "        fps=fps,\n",
        "        frame_count=total_frames,\n",
        "        confidences=confidences,\n",
        "        sample_rate=sample_rate,\n",
        "    )\n",
        "    video_obj.attach_tensor(tensor)\n",
        "    return tensor\n",
        "\n",
        "\n",
        "import csv\n",
        "CSV_PATH = PROJECT_ROOT / \"tensor_index.csv\"\n",
        "\n",
        "\n",
        "def write_video_tensor_csv(video_objs, csv_path=CSV_PATH):\n",
        "    \"\"\"Write rows: [video_path, c0, c1, ..., cN] using attached tensors.\"\"\"\n",
        "    with open(csv_path, \"w\", newline=\"\") as f:\n",
        "        w = csv.writer(f)\n",
        "        w.writerow([\"video_path\", \"confidences...\"])  # header\n",
        "        for vo in video_objs:\n",
        "            if vo.tensor is None:\n",
        "                continue\n",
        "            row = [str(vo.video_path)] + [float(x) for x in vo.tensor.confidences]\n",
        "            w.writerow(row)\n",
        "    print(f\"Wrote CSV: {csv_path}\")\n",
        "\n",
        "\n",
        "def read_video_tensor_csv(csv_path=CSV_PATH):\n",
        "    \"\"\"Read CSV back into {video_path: np.ndarray(confidences)} mapping.\"\"\"\n",
        "    data = {}\n",
        "    with open(csv_path, \"r\", newline=\"\") as f:\n",
        "        r = csv.reader(f)\n",
        "        header = next(r, None)\n",
        "        for row in r:\n",
        "            video_path = row[0]\n",
        "            confs = np.array([float(x) for x in row[1:]], dtype=np.float32)\n",
        "            data[video_path] = confs\n",
        "    return data\n",
        "\n",
        "\n",
        "def build_all_tensors_and_write_csv():\n",
        "    \"\"\"Compute tensors for train/val/test (if enough videos) and write CSV.\"\"\"\n",
        "    if len(video_objs) < TOTAL_REQ:\n",
        "        print(f\"Add more videos to the 'videos' folder (need >= {TOTAL_REQ}).\")\n",
        "        return\n",
        "    print(\"Building tensors for training set...\")\n",
        "    for vo in train_videos:\n",
        "        _ = process_video_to_tensor(vo)\n",
        "    print(\"Building tensors for validation set...\")\n",
        "    for vo in val_videos:\n",
        "        _ = process_video_to_tensor(vo)\n",
        "    print(\"Building tensors for test set...\")\n",
        "    for vo in test_videos:\n",
        "        _ = process_video_to_tensor(vo)\n",
        "    write_video_tensor_csv(train_videos + val_videos + test_videos)\n",
        "    print(\"All tensors built and CSV written.\")\n",
        "\n",
        "\n",
        "build_all_tensors_and_write_csv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "IW7zdYqFSl98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IW7zdYqFSl98",
        "outputId": "c97955cc-4886-4fc4-93e2-ea36d9180028"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Loading tensors from /content/balltime/tensor_index.csv...\n",
            "Loaded 8 tensor sets\n",
            "Loading labels from /content/balltime/video_true_labels.csv...\n",
            "Loaded 21 label sets\n",
            "Aligned 8 video sets\n",
            "Model: BallDetectionCNN(\n",
            "  (conv1): Conv1d(1, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (drop): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=960, out_features=32, bias=True)\n",
            "  (head): Linear(in_features=32, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "TRAIN: 28023 high-variance windows from 5 videos\n",
            "VAL: 6275 high-variance windows from 1 videos\n",
            "TEST: 11385 high-variance windows from 2 videos\n",
            "\n",
            "=== Epoch 1/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 317.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.7454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 669.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.6794 | Val Acc: 0.7739\n",
            "✅ Best model saved (val_loss=0.6794)\n",
            "\n",
            "=== Epoch 2/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 310.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.7211\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 685.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.6869 | Val Acc: 0.7739\n",
            "\n",
            "=== Epoch 3/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 320.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.7188\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 680.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.6966 | Val Acc: 0.7739\n",
            "\n",
            "=== Epoch 4/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 319.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.7163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 669.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.6938 | Val Acc: 0.7739\n",
            "\n",
            "=== Epoch 5/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 316.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.7148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 648.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.6996 | Val Acc: 0.7739\n",
            "\n",
            "=== Epoch 6/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 319.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.7123\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 671.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.7037 | Val Acc: 0.7739\n",
            "\n",
            "=== Epoch 7/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 317.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.7058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 666.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.7366 | Val Acc: 0.7726\n",
            "\n",
            "=== Epoch 8/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 318.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.7001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 674.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.7592 | Val Acc: 0.7723\n",
            "\n",
            "=== Epoch 9/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 315.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6947\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 669.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.7606 | Val Acc: 0.7705\n",
            "\n",
            "=== Epoch 10/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 313.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6906\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 678.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.7592 | Val Acc: 0.7705\n",
            "\n",
            "=== Epoch 11/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 319.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6878\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 664.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.8057 | Val Acc: 0.7667\n",
            "\n",
            "=== Epoch 12/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 316.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6835\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 673.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.8173 | Val Acc: 0.7603\n",
            "\n",
            "=== Epoch 13/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 314.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6806\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 679.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.8706 | Val Acc: 0.7592\n",
            "\n",
            "=== Epoch 14/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 312.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 673.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.8632 | Val Acc: 0.7600\n",
            "\n",
            "=== Epoch 15/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 313.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 680.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.8927 | Val Acc: 0.7589\n",
            "\n",
            "=== Epoch 16/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 310.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6697\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 665.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.9079 | Val Acc: 0.7589\n",
            "\n",
            "=== Epoch 17/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 311.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 653.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.9202 | Val Acc: 0.7543\n",
            "\n",
            "=== Epoch 18/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 320.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 671.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.9684 | Val Acc: 0.7517\n",
            "\n",
            "=== Epoch 19/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 317.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6620\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 670.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.9845 | Val Acc: 0.7508\n",
            "\n",
            "=== Epoch 20/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 323.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6589\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 647.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.0199 | Val Acc: 0.7512\n",
            "\n",
            "=== Epoch 21/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 315.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 654.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.0203 | Val Acc: 0.7543\n",
            "\n",
            "=== Epoch 22/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 309.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6579\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 667.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.0438 | Val Acc: 0.7517\n",
            "\n",
            "=== Epoch 23/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 316.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6560\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 666.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.0643 | Val Acc: 0.7508\n",
            "\n",
            "=== Epoch 24/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 322.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 652.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.0748 | Val Acc: 0.7520\n",
            "\n",
            "=== Epoch 25/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 315.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6529\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 647.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.0966 | Val Acc: 0.7498\n",
            "\n",
            "=== Epoch 26/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 319.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6517\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 676.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.0751 | Val Acc: 0.7485\n",
            "\n",
            "=== Epoch 27/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 316.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 679.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.0994 | Val Acc: 0.7503\n",
            "\n",
            "=== Epoch 28/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 310.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 663.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.1200 | Val Acc: 0.7506\n",
            "\n",
            "=== Epoch 29/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 311.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6497\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 656.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.1235 | Val Acc: 0.7498\n",
            "\n",
            "=== Epoch 30/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 318.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6510\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 677.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.1356 | Val Acc: 0.7480\n",
            "\n",
            "=== Epoch 31/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 319.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 668.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.1371 | Val Acc: 0.7477\n",
            "\n",
            "=== Epoch 32/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 318.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6478\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 667.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.1580 | Val Acc: 0.7492\n",
            "\n",
            "=== Epoch 33/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 314.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 662.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.1624 | Val Acc: 0.7485\n",
            "\n",
            "=== Epoch 34/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 315.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 671.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.1623 | Val Acc: 0.7480\n",
            "\n",
            "=== Epoch 35/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 318.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6463\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 674.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.1747 | Val Acc: 0.7485\n",
            "\n",
            "=== Epoch 36/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 315.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 673.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.1826 | Val Acc: 0.7477\n",
            "\n",
            "=== Epoch 37/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 313.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6458\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 671.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.1801 | Val Acc: 0.7480\n",
            "\n",
            "=== Epoch 38/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 317.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 666.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.1844 | Val Acc: 0.7474\n",
            "\n",
            "=== Epoch 39/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 325.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 682.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.1829 | Val Acc: 0.7474\n",
            "\n",
            "=== Epoch 40/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 316.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6456\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 666.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.1931 | Val Acc: 0.7474\n",
            "\n",
            "=== Epoch 41/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 313.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 610.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.1974 | Val Acc: 0.7473\n",
            "\n",
            "=== Epoch 42/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 318.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6460\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 679.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.1834 | Val Acc: 0.7479\n",
            "\n",
            "=== Epoch 43/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 317.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 663.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.2008 | Val Acc: 0.7477\n",
            "\n",
            "=== Epoch 44/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 311.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6456\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 619.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.2031 | Val Acc: 0.7479\n",
            "\n",
            "=== Epoch 45/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 307.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 673.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.2060 | Val Acc: 0.7468\n",
            "\n",
            "=== Epoch 46/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 320.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6433\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 684.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.2083 | Val Acc: 0.7474\n",
            "\n",
            "=== Epoch 47/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 316.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6442\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 678.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.2037 | Val Acc: 0.7479\n",
            "\n",
            "=== Epoch 48/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 311.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 658.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.2030 | Val Acc: 0.7477\n",
            "\n",
            "=== Epoch 49/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 305.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 668.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.2112 | Val Acc: 0.7474\n",
            "\n",
            "=== Epoch 50/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 876/876 [00:02<00:00, 314.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6433\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 197/197 [00:00<00:00, 670.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 1.2081 | Val Acc: 0.7474\n",
            "\n",
            "=== Training Complete ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 356/356 [00:00<00:00, 658.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🧪 Test Loss: 0.7184 | Test Accuracy: 0.7519\n",
            "✅ Training history saved to /content/balltime/training_history.csv\n",
            "✅ Training curves saved to /content/balltime/training_curves.png\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ============================================================================\n",
        "# 1. HYPERPARAMETERS & SETUP\n",
        "# ============================================================================\n",
        "\n",
        "WINDOW_LENGTH = 120  # ~8 seconds at 7.5 effective FPS (30 FPS / stride 4)\n",
        "STRIDE = 2  # Original stride from inference\n",
        "EFFECTIVE_FPS = 30 / STRIDE  # 7.5 fps\n",
        "ORIGINAL_FPS = 30\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 50\n",
        "LEARNING_RATE = 5e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "\n",
        "# Positive weight for imbalanced data (adjust if needed)\n",
        "POS_WEIGHT = torch.tensor([2.0])  # Increase if minority class (ball=1) is rare\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 2. LOAD TENSORS & LABELS FROM CSV\n",
        "# ============================================================================\n",
        "\n",
        "def load_tensors_from_csv(csv_path):\n",
        "    \"\"\"Load confidence tensors from tensor_index.csv (handles variable lengths)\"\"\"\n",
        "    tensors = {}\n",
        "    with open(csv_path, 'r') as f:\n",
        "        header = f.readline().strip().split(',')\n",
        "        for line in f:\n",
        "            parts = line.strip().split(',')\n",
        "            video_path = parts[0]\n",
        "            confs = np.array([float(x) for x in parts[1:]], dtype=np.float32)\n",
        "            tensors[video_path] = confs\n",
        "    return tensors\n",
        "\n",
        "def load_labels_from_csv(csv_path):\n",
        "    \"\"\"Load binary labels from video_true_labels.csv (handles variable lengths)\"\"\"\n",
        "    labels = {}\n",
        "    with open(csv_path, 'r') as f:\n",
        "        header = f.readline().strip().split(',')\n",
        "        for line in f:\n",
        "            parts = line.strip().split(',')\n",
        "            video_name = parts[0]\n",
        "            label_array = np.array([int(x) for x in parts[1:]], dtype=np.int64)\n",
        "            labels[video_name] = label_array\n",
        "    return labels\n",
        "\n",
        "# Load data\n",
        "TENSOR_CSV = PROJECT_ROOT / \"tensor_index.csv\"\n",
        "LABEL_CSV = PROJECT_ROOT / \"video_true_labels.csv\"\n",
        "\n",
        "print(f\"Loading tensors from {TENSOR_CSV}...\")\n",
        "tensors_dict = load_tensors_from_csv(TENSOR_CSV)\n",
        "print(f\"Loaded {len(tensors_dict)} tensor sets\")\n",
        "\n",
        "print(f\"Loading labels from {LABEL_CSV}...\")\n",
        "labels_dict = load_labels_from_csv(LABEL_CSV)\n",
        "print(f\"Loaded {len(labels_dict)} label sets\")\n",
        "\n",
        "# ============================================================================\n",
        "# 3. ALIGN TENSORS & LABELS (DOWNSAMPLE LABELS TO MATCH TENSORS)\n",
        "# ============================================================================\n",
        "\n",
        "def downsample_labels_to_tensors(labels, stride=STRIDE):\n",
        "    \"\"\"\n",
        "    Downsample labels from original frames to tensor indices.\n",
        "    tensor[i] corresponds to original frame [i * stride].\n",
        "    label[i * stride] → tensor_label[i]\n",
        "    \"\"\"\n",
        "    downsampled = labels[::stride]\n",
        "    return downsampled\n",
        "\n",
        "# Prepare aligned data\n",
        "aligned_data = {}\n",
        "for video_path, tensor in tensors_dict.items():\n",
        "    video_name = Path(video_path).name\n",
        "    if video_name in labels_dict:\n",
        "        labels = labels_dict[video_name]\n",
        "        ds_labels = downsample_labels_to_tensors(labels, stride=STRIDE)\n",
        "        # Ensure lengths match (truncate if needed)\n",
        "        min_len = min(len(tensor), len(ds_labels))\n",
        "        aligned_data[video_path] = {\n",
        "            \"tensor\": tensor[:min_len],\n",
        "            \"label\": ds_labels[:min_len]\n",
        "        }\n",
        "    else:\n",
        "        print(f\"⚠ Warning: No labels found for {video_name}\")\n",
        "\n",
        "print(f\"Aligned {len(aligned_data)} video sets\")\n",
        "\n",
        "# ============================================================================\n",
        "# 4. DATASET CLASS\n",
        "# ============================================================================\n",
        "\n",
        "class HighVarianceDataset(Dataset):\n",
        "    \"\"\"Sample high-variance windows from given video list\"\"\"\n",
        "    def __init__(self, video_list, aligned_data, window_length=WINDOW_LENGTH,\n",
        "                 variance_threshold=0.05, split=\"train\"):\n",
        "        self.video_list = video_list\n",
        "        self.aligned_data = aligned_data\n",
        "        self.window_length = window_length\n",
        "        self.variance_threshold = variance_threshold\n",
        "        self.split = split\n",
        "\n",
        "        # Find high-variance windows ONLY in the given video_list\n",
        "        self.high_var_pairs = []\n",
        "        for video_path in video_list:  # Use pre-split list\n",
        "            if video_path in aligned_data:\n",
        "                label = aligned_data[video_path][\"label\"].astype(float)\n",
        "                T = len(label)\n",
        "\n",
        "                for t in range(window_length // 2, T - window_length // 2):\n",
        "                    start = t - window_length // 2\n",
        "                    end = start + window_length\n",
        "                    window_labels = label[start:end]\n",
        "                    variance = window_labels.var()\n",
        "\n",
        "                    if variance > variance_threshold:\n",
        "                        self.high_var_pairs.append((video_path, t, variance))\n",
        "\n",
        "        self.high_var_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "        print(f\"{split.upper()}: {len(self.high_var_pairs)} high-variance windows \" +\n",
        "              f\"from {len(video_list)} videos\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.high_var_pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        video_path, center_t, _ = self.high_var_pairs[idx]\n",
        "        data = self.aligned_data[video_path]\n",
        "        tensor = data[\"tensor\"]\n",
        "        label = data[\"label\"]\n",
        "\n",
        "        start = center_t - self.window_length // 2\n",
        "        end = start + self.window_length\n",
        "\n",
        "        X = tensor[start:end].astype(np.float32)\n",
        "        y = label[center_t].astype(np.float32)\n",
        "\n",
        "        return {\n",
        "            \"X\": torch.tensor(X, dtype=torch.float32),\n",
        "            \"y\": torch.tensor(y, dtype=torch.float32),\n",
        "            \"video\": str(video_path),\n",
        "            \"center_t\": center_t\n",
        "        }\n",
        "\n",
        "# ============================================================================\n",
        "# 5. MODEL\n",
        "# ============================================================================\n",
        "\n",
        "class BallDetectionCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    2-layer 1D CNN for ball detection on confidence windows.\n",
        "    Input: (B, 1, L) where L=16 timesteps\n",
        "    Output: (B, 1) logits for binary classification\n",
        "    \"\"\"\n",
        "    def __init__(self, window_length=WINDOW_LENGTH):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=5, padding=2)\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
        "        self.drop = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(16 * (window_length // 2), 32)  # was 64\n",
        "        self.head = nn.Linear(32, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, L) -> (B, 1, L)\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.relu(self.conv1(x))  # (B, 16, L)\n",
        "        x = self.pool(x)               # (B, 16, L/2)\n",
        "        x = x.view(x.size(0), -1)      # (B, 16*(L/2))\n",
        "        x = self.relu(self.fc(x))       # (B, 64)\n",
        "        x = self.drop(x)\n",
        "        logits = self.head(x)           # (B, 1)\n",
        "        return logits.squeeze(1)        # (B,)\n",
        "\n",
        "model = BallDetectionCNN(window_length=WINDOW_LENGTH).to(DEVICE)\n",
        "print(f\"Model: {model}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 6. LOSS & OPTIMIZER\n",
        "# ============================================================================\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=POS_WEIGHT.to(DEVICE))\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "# ============================================================================\n",
        "# 7. TRAIN & EVAL FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def train_epoch(dataloader, model, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
        "        X = batch[\"X\"].to(device)\n",
        "        y = batch[\"y\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(X)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_epoch(dataloader, model, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "        X = batch[\"X\"].to(device)\n",
        "        y = batch[\"y\"].to(device)\n",
        "\n",
        "        logits = model(X)\n",
        "        loss = criterion(logits, y)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        probs = torch.sigmoid(logits).cpu().numpy()\n",
        "        all_preds.append(probs)\n",
        "        all_labels.append(y.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "\n",
        "    # Compute accuracy\n",
        "    pred_binary = (all_preds > 0.5).astype(int)\n",
        "    accuracy = (pred_binary == all_labels).mean()\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# ============================================================================\n",
        "# 8. SPLIT & CREATE DATALOADERS\n",
        "# ============================================================================\n",
        "\n",
        "# Get video paths from train/val/test splits\n",
        "train_paths = [str(v.video_path) for v in train_videos]\n",
        "val_paths = [str(v.video_path) for v in val_videos]\n",
        "test_paths = [str(v.video_path) for v in test_videos]\n",
        "\n",
        "# Use existing train_paths, val_paths, test_paths from cell 5\n",
        "train_dataset = HighVarianceDataset(\n",
        "    train_paths, aligned_data, window_length=WINDOW_LENGTH,\n",
        "    variance_threshold=0.05, split=\"train\"\n",
        ")\n",
        "val_dataset = HighVarianceDataset(\n",
        "    val_paths, aligned_data, window_length=WINDOW_LENGTH,\n",
        "    variance_threshold=0.05, split=\"val\"\n",
        ")\n",
        "test_dataset = HighVarianceDataset(\n",
        "    test_paths, aligned_data, window_length=WINDOW_LENGTH,\n",
        "    variance_threshold=0.05, split=\"test\"\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# ============================================================================\n",
        "# 9. TRAINING LOOP\n",
        "# ============================================================================\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"\\n=== Epoch {epoch+1}/{NUM_EPOCHS} ===\")\n",
        "\n",
        "    # Train\n",
        "    train_loss = train_epoch(train_loader, model, criterion, optimizer, DEVICE)\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "    print(f\"Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "    # Validate\n",
        "    val_loss, val_acc = eval_epoch(val_loader, model, criterion, DEVICE)\n",
        "    history[\"val_loss\"].append(val_loss)\n",
        "    history[\"val_acc\"].append(val_acc)\n",
        "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    # Learning rate scheduling\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Save best model\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), PROJECT_ROOT / \"best_model.pth\")\n",
        "        print(f\"✅ Best model saved (val_loss={val_loss:.4f})\")\n",
        "\n",
        "print(\"\\n=== Training Complete ===\")\n",
        "\n",
        "# ============================================================================\n",
        "# 10. TEST EVALUATION\n",
        "# ============================================================================\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load(PROJECT_ROOT / \"best_model.pth\"))\n",
        "test_loss, test_acc = eval_epoch(test_loader, model, criterion, DEVICE)\n",
        "print(f\"\\n🧪 Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 11. SAVE TRAINING HISTORY\n",
        "# ============================================================================\n",
        "\n",
        "history_df = pd.DataFrame(history)\n",
        "history_df.to_csv(PROJECT_ROOT / \"training_history.csv\", index=False)\n",
        "print(f\"✅ Training history saved to {PROJECT_ROOT / 'training_history.csv'}\")\n",
        "\n",
        "# Plot (optional)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
        "plt.plot(history[\"val_loss\"], label=\"Val Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history[\"val_acc\"], label=\"Val Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.tight_layout()\n",
        "plt.savefig(PROJECT_ROOT / \"training_curves.png\")\n",
        "print(f\"✅ Training curves saved to {PROJECT_ROOT / 'training_curves.png'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "9t--9GFCXsrE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t--9GFCXsrE",
        "outputId": "9b39d23e-8374-4c08-d839-8eaea25c8955"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "TEST SET INFERENCE & PLAY DETECTION\n",
            "================================================================================\n",
            "\n",
            "📹 Processing: BHPU1.mp4\n",
            "   Tensor length: 10913 timesteps (~727.5 seconds)\n",
            "   Running inference...\n",
            "   Thresholding predictions...\n",
            "   Removing islands...\n",
            "   Extracting play intervals...\n",
            "   ✅ Found 1 plays:\n",
            "      Play 1: 0.0s - 727.47s (727.47s) | Frames 0-21824\n",
            "\n",
            "📹 Processing: BUNCGB22.mp4\n",
            "   Tensor length: 8810 timesteps (~587.3 seconds)\n",
            "   Running inference...\n",
            "   Thresholding predictions...\n",
            "   Removing islands...\n",
            "   Extracting play intervals...\n",
            "   ✅ Found 1 plays:\n",
            "      Play 1: 0.0s - 587.27s (587.27s) | Frames 0-17618\n",
            "\n",
            "✅ Test results saved to /content/balltime/test_play_detections.csv\n",
            "\n",
            "Summary:\n",
            "  Total plays detected: 2\n",
            "  Average play duration: 657.37s\n",
            "\n",
            "          video  start_sec  end_sec  duration_sec  start_frame  end_frame\n",
            "0     BHPU1.mp4        0.0   727.47        727.47            0      21824\n",
            "1  BUNCGB22.mp4        0.0   587.27        587.27            0      17618\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# TEST INFERENCE: RUN MODEL & EXTRACT PLAY INTERVALS\n",
        "# ============================================================================\n",
        "\n",
        "from scipy import ndimage\n",
        "\n",
        "# Hyperparameters\n",
        "CONFIDENCE_THRESHOLD = 0.3  # Threshold for \"in-play\"\n",
        "MIN_ISLAND_FRAMES = 5  # Remove islands smaller than this (in timesteps)\n",
        "MIN_PLAY_DURATION = 1  # Minimum play length in seconds (filter noise)\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load(PROJECT_ROOT / \"best_model.pth\"))\n",
        "model.eval()\n",
        "\n",
        "# ============================================================================\n",
        "# RUN INFERENCE ON TEST VIDEOS\n",
        "# ============================================================================\n",
        "\n",
        "def predict_on_tensor(tensor, model, device, window_length=WINDOW_LENGTH):\n",
        "    \"\"\"\n",
        "    Slide window over entire tensor and predict for each position.\n",
        "    Returns: (T,) array of probabilities\n",
        "    \"\"\"\n",
        "    T = len(tensor)\n",
        "    predictions = np.zeros(T, dtype=np.float32)\n",
        "\n",
        "    # Pad tensor for boundary handling\n",
        "    pad_size = window_length // 2\n",
        "    tensor_padded = np.pad(tensor, (pad_size, pad_size), mode='edge')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for t in range(T):\n",
        "            # Extract window\n",
        "            window = tensor_padded[t : t + window_length]\n",
        "            X = torch.tensor(window, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "            logits = model(X)\n",
        "            probs = torch.sigmoid(logits).cpu().numpy()\n",
        "            predictions[t] = probs[0]\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def remove_islands(binary_array, min_duration_frames=MIN_ISLAND_FRAMES):\n",
        "    \"\"\"Remove isolated True regions smaller than min_duration_frames\"\"\"\n",
        "    labeled, num_features = ndimage.label(binary_array)\n",
        "    cleaned = binary_array.copy()\n",
        "    for label_id in range(1, num_features + 1):\n",
        "        component = (labeled == label_id)\n",
        "        if component.sum() < min_duration_frames:\n",
        "            cleaned[component] = 0\n",
        "    return cleaned\n",
        "\n",
        "def extract_play_intervals(binary_predictions, min_duration_sec=MIN_PLAY_DURATION,\n",
        "                          fps=EFFECTIVE_FPS):\n",
        "    \"\"\"\n",
        "    Extract start/end timestamps (in seconds) for plays.\n",
        "    Input: binary array (0/1) already thresholded\n",
        "    \"\"\"\n",
        "    # Find transitions\n",
        "    diff = np.diff(binary_predictions, prepend=0)\n",
        "    starts_idx = np.where(diff == 1)[0]\n",
        "    ends_idx = np.where(diff == -1)[0]\n",
        "\n",
        "    # Ensure paired start/end\n",
        "    if len(starts_idx) > len(ends_idx):\n",
        "        ends_idx = np.append(ends_idx, len(binary_predictions) - 1)\n",
        "\n",
        "    # Filter by minimum duration\n",
        "    plays = []\n",
        "    for start_idx, end_idx in zip(starts_idx, ends_idx):\n",
        "        duration_sec = (end_idx - start_idx) / fps\n",
        "        if duration_sec >= min_duration_sec:\n",
        "            start_sec = start_idx / fps\n",
        "            end_sec = end_idx / fps\n",
        "            plays.append((start_sec, end_sec, duration_sec))\n",
        "\n",
        "    return plays\n",
        "\n",
        "# ============================================================================\n",
        "# PROCESS ALL TEST VIDEOS\n",
        "# ============================================================================\n",
        "\n",
        "test_results = []\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TEST SET INFERENCE & PLAY DETECTION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for video_path in test_paths:\n",
        "    if video_path not in aligned_data:\n",
        "        print(f\"⚠ Skipping {video_path} (not in aligned data)\")\n",
        "        continue\n",
        "\n",
        "    video_name = Path(video_path).name\n",
        "    tensor = aligned_data[video_path][\"tensor\"]\n",
        "\n",
        "    print(f\"\\n📹 Processing: {video_name}\")\n",
        "    print(f\"   Tensor length: {len(tensor)} timesteps (~{len(tensor)/EFFECTIVE_FPS:.1f} seconds)\")\n",
        "\n",
        "    # Inference\n",
        "    print(\"   Running inference...\")\n",
        "    predictions = predict_on_tensor(tensor, model, DEVICE, window_length=WINDOW_LENGTH)\n",
        "\n",
        "    # Threshold\n",
        "    print(\"   Thresholding predictions...\")\n",
        "    binary = (predictions > CONFIDENCE_THRESHOLD).astype(int)\n",
        "\n",
        "    # Remove islands\n",
        "    print(\"   Removing islands...\")\n",
        "    cleaned = remove_islands(binary, min_duration_frames=MIN_ISLAND_FRAMES)\n",
        "\n",
        "    # Extract plays\n",
        "    print(\"   Extracting play intervals...\")\n",
        "    plays = extract_play_intervals(cleaned, min_duration_sec=MIN_PLAY_DURATION,\n",
        "                                   fps=EFFECTIVE_FPS)\n",
        "\n",
        "    # Map back to original frame indices\n",
        "    plays_in_frames = []\n",
        "    for start_sec, end_sec, dur_sec in plays:\n",
        "        start_frame = int(start_sec * ORIGINAL_FPS)\n",
        "        end_frame = int(end_sec * ORIGINAL_FPS)\n",
        "        plays_in_frames.append({\n",
        "            \"video\": video_name,\n",
        "            \"start_sec\": round(start_sec, 2),\n",
        "            \"end_sec\": round(end_sec, 2),\n",
        "            \"duration_sec\": round(dur_sec, 2),\n",
        "            \"start_frame\": start_frame,\n",
        "            \"end_frame\": end_frame,\n",
        "        })\n",
        "\n",
        "    print(f\"   ✅ Found {len(plays)} plays:\")\n",
        "    for i, play in enumerate(plays_in_frames, 1):\n",
        "        print(f\"      Play {i}: {play['start_sec']}s - {play['end_sec']}s \" +\n",
        "              f\"({play['duration_sec']}s) | Frames {play['start_frame']}-{play['end_frame']}\")\n",
        "\n",
        "    test_results.extend(plays_in_frames)\n",
        "\n",
        "# ============================================================================\n",
        "# SAVE RESULTS\n",
        "# ============================================================================\n",
        "\n",
        "results_df = pd.DataFrame(test_results)\n",
        "results_csv = PROJECT_ROOT / \"test_play_detections.csv\"\n",
        "results_df.to_csv(results_csv, index=False)\n",
        "print(f\"\\n✅ Test results saved to {results_csv}\")\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"  Total plays detected: {len(test_results)}\")\n",
        "if len(test_results) > 0:\n",
        "    print(f\"  Average play duration: {results_df['duration_sec'].mean():.2f}s\")\n",
        "print(f\"\\n{results_df}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
