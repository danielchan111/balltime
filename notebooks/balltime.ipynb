{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f17066a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'balltime'...\n",
      "remote: Enumerating objects: 73, done.\u001b[K\n",
      "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
      "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
      "remote: Total 73 (delta 12), reused 71 (delta 10), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (73/73), 62.40 KiB | 1014.00 KiB/s, done.\n",
      "Resolving deltas: 100% (12/12), done.\n",
      "/content/balltime\n",
      "CWD: /content/balltime\n",
      "Files here: ['.DS_Store', 'notebooks', 'models', '.git', 'requirements.txt']\n",
      "remote: Enumerating objects: 73, done.\u001b[K\n",
      "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
      "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
      "remote: Total 73 (delta 12), reused 71 (delta 10), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (73/73), 62.40 KiB | 1014.00 KiB/s, done.\n",
      "Resolving deltas: 100% (12/12), done.\n",
      "/content/balltime\n",
      "CWD: /content/balltime\n",
      "Files here: ['.DS_Store', 'notebooks', 'models', '.git', 'requirements.txt']\n"
     ]
    }
   ],
   "source": [
    "!rm -rf balltime\n",
    "!git clone https://github.com/danielchan111/balltime.git\n",
    "%cd balltime\n",
    "\n",
    "from pathlib import Path\n",
    "print(\"CWD:\", Path.cwd())\n",
    "print(\"Files here:\", [p.name for p in Path('.').iterdir()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dca182af",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/facebookresearch/pytorchvideo (from -r requirements.txt (line 23))\n",
      "  Cloning https://github.com/facebookresearch/pytorchvideo to /tmp/pip-req-build-ewvfj6zp\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/pytorchvideo /tmp/pip-req-build-ewvfj6zp\n",
      "  Resolved https://github.com/facebookresearch/pytorchvideo to commit 0f9a5e102e4d84972b829fd30e3c3f78c7c7fd1a\n",
      "  Resolved https://github.com/facebookresearch/pytorchvideo to commit 0f9a5e102e4d84972b829fd30e3c3f78c7c7fd1a\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: scipy==1.11.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn==1.3.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (2.9.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (0.24.0+cu126)\n",
      "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (8.3.237)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (4.57.3)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (4.11.0.86)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (11.3.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (2.2.2)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (0.13.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (4.67.1)\n",
      "Requirement already satisfied: supervision in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (0.27.0)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (0.6.7)\n",
      "Requirement already satisfied: norfair in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (2.3.0)\n",
      "Requirement already satisfied: filterpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (1.4.5)\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 19)) (5.2.0)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 20)) (2.12.3)\n",
      "Requirement already satisfied: pydantic-settings in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 21)) (2.12.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.2->-r requirements.txt (line 3)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.2->-r requirements.txt (line 3)) (3.6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (3.1.6)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: scipy==1.11.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn==1.3.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (2.9.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (0.24.0+cu126)\n",
      "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (8.3.237)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (4.57.3)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (4.11.0.86)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (11.3.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (2.2.2)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (0.13.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (4.67.1)\n",
      "Requirement already satisfied: supervision in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (0.27.0)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (0.6.7)\n",
      "Requirement already satisfied: norfair in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (2.3.0)\n",
      "Requirement already satisfied: filterpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (1.4.5)\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 19)) (5.2.0)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 20)) (2.12.3)\n",
      "Requirement already satisfied: pydantic-settings in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 21)) (2.12.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.2->-r requirements.txt (line 3)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.2->-r requirements.txt (line 3)) (3.6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (3.5.0)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics->-r requirements.txt (line 7)) (3.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics->-r requirements.txt (line 7)) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics->-r requirements.txt (line 7)) (2.32.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics->-r requirements.txt (line 7)) (5.9.5)\n",
      "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics->-r requirements.txt (line 7)) (1.31.0)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in /usr/local/lib/python3.12/dist-packages (from ultralytics->-r requirements.txt (line 7)) (2.0.18)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 8)) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 8)) (25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 8)) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 8)) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 11)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 11)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 11)) (2025.2)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from supervision->-r requirements.txt (line 14)) (0.7.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->-r requirements.txt (line 16)) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->-r requirements.txt (line 16)) (0.9.0)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 5)) (3.5.0)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics->-r requirements.txt (line 7)) (3.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics->-r requirements.txt (line 7)) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics->-r requirements.txt (line 7)) (2.32.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics->-r requirements.txt (line 7)) (5.9.5)\n",
      "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics->-r requirements.txt (line 7)) (1.31.0)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in /usr/local/lib/python3.12/dist-packages (from ultralytics->-r requirements.txt (line 7)) (2.0.18)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 8)) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 8)) (25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 8)) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 8)) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 11)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 11)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 11)) (2025.2)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from supervision->-r requirements.txt (line 14)) (0.7.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->-r requirements.txt (line 16)) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->-r requirements.txt (line 16)) (0.9.0)\n",
      "Requirement already satisfied: rich<15.0.0,>=9.10.0 in /usr/local/lib/python3.12/dist-packages (from norfair->-r requirements.txt (line 17)) (13.9.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown->-r requirements.txt (line 19)) (4.13.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r requirements.txt (line 20)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r requirements.txt (line 20)) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r requirements.txt (line 20)) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings->-r requirements.txt (line 21)) (1.2.1)\n",
      "Requirement already satisfied: fvcore in /usr/local/lib/python3.12/dist-packages (from pytorchvideo==0.1.5->-r requirements.txt (line 23)) (0.1.5.post20221221)\n",
      "Requirement already satisfied: av in /usr/local/lib/python3.12/dist-packages (from pytorchvideo==0.1.5->-r requirements.txt (line 23)) (16.0.1)\n",
      "Requirement already satisfied: parameterized in /usr/local/lib/python3.12/dist-packages (from pytorchvideo==0.1.5->-r requirements.txt (line 23)) (0.9.0)\n",
      "Requirement already satisfied: iopath in /usr/local/lib/python3.12/dist-packages (from pytorchvideo==0.1.5->-r requirements.txt (line 23)) (0.1.10)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements.txt (line 8)) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 7)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 7)) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 7)) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 7)) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 11)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 7)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 7)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 7)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 7)) (2025.11.12)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=9.10.0->norfair->-r requirements.txt (line 17)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=9.10.0->norfair->-r requirements.txt (line 17)) (2.19.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->-r requirements.txt (line 16)) (1.1.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown->-r requirements.txt (line 19)) (2.8)\n",
      "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from fvcore->pytorchvideo==0.1.5->-r requirements.txt (line 23)) (0.1.8)\n",
      "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.12/dist-packages (from fvcore->pytorchvideo==0.1.5->-r requirements.txt (line 23)) (3.2.0)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from fvcore->pytorchvideo==0.1.5->-r requirements.txt (line 23)) (0.9.0)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from iopath->pytorchvideo==0.1.5->-r requirements.txt (line 23)) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements.txt (line 5)) (3.0.3)\n",
      "Requirement already satisfied: rich<15.0.0,>=9.10.0 in /usr/local/lib/python3.12/dist-packages (from norfair->-r requirements.txt (line 17)) (13.9.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown->-r requirements.txt (line 19)) (4.13.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r requirements.txt (line 20)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r requirements.txt (line 20)) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r requirements.txt (line 20)) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings->-r requirements.txt (line 21)) (1.2.1)\n",
      "Requirement already satisfied: fvcore in /usr/local/lib/python3.12/dist-packages (from pytorchvideo==0.1.5->-r requirements.txt (line 23)) (0.1.5.post20221221)\n",
      "Requirement already satisfied: av in /usr/local/lib/python3.12/dist-packages (from pytorchvideo==0.1.5->-r requirements.txt (line 23)) (16.0.1)\n",
      "Requirement already satisfied: parameterized in /usr/local/lib/python3.12/dist-packages (from pytorchvideo==0.1.5->-r requirements.txt (line 23)) (0.9.0)\n",
      "Requirement already satisfied: iopath in /usr/local/lib/python3.12/dist-packages (from pytorchvideo==0.1.5->-r requirements.txt (line 23)) (0.1.10)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements.txt (line 8)) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 7)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 7)) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 7)) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 7)) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 11)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 7)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 7)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 7)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 7)) (2025.11.12)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=9.10.0->norfair->-r requirements.txt (line 17)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=9.10.0->norfair->-r requirements.txt (line 17)) (2.19.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->-r requirements.txt (line 16)) (1.1.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown->-r requirements.txt (line 19)) (2.8)\n",
      "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from fvcore->pytorchvideo==0.1.5->-r requirements.txt (line 23)) (0.1.8)\n",
      "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.12/dist-packages (from fvcore->pytorchvideo==0.1.5->-r requirements.txt (line 23)) (3.2.0)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from fvcore->pytorchvideo==0.1.5->-r requirements.txt (line 23)) (0.9.0)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from iopath->pytorchvideo==0.1.5->-r requirements.txt (line 23)) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements.txt (line 5)) (3.0.3)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 19)) (1.7.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=9.10.0->norfair->-r requirements.txt (line 17)) (0.1.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 19)) (1.7.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=9.10.0->norfair->-r requirements.txt (line 17)) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f136162",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "\u001b[32mINFO: ML Manager initialized on device: cuda:0\u001b[0m\n",
      "\u001b[32mINFO: ML Manager initialized on device: cuda:0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:ml_manager:ML Manager initialized on device: cuda:0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO: Using default weights configuration\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:ml_manager:Using default weights configuration\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO: Initializing deep learning models...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:ml_manager:Initializing deep learning models...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO: Missing model weights detected: ['ball_detection', 'action_detection', 'court_detection', 'game_state']\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:ml_manager:Missing model weights detected: ['ball_detection', 'action_detection', 'court_detection', 'game_state']\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO: Downloading missing weights from Google Drive...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:ml_manager:Downloading missing weights from Google Drive...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO: Downloading complete weights ZIP file from Google Drive...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:ml_manager:Downloading complete weights ZIP file from Google Drive...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO: Downloading from Google Drive (ID: 1__zkTmGwZo2z0EgbJvC14I_3kOpgQx3o) to /content/balltime/weights/all_weights.zip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:ml_manager:Downloading from Google Drive (ID: 1__zkTmGwZo2z0EgbJvC14I_3kOpgQx3o) to /content/balltime/weights/all_weights.zip\u001b[0m\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1__zkTmGwZo2z0EgbJvC14I_3kOpgQx3o\n",
      "From (redirected): https://drive.google.com/uc?id=1__zkTmGwZo2z0EgbJvC14I_3kOpgQx3o&confirm=t&uuid=f126d249-1b98-4fdc-88b0-336ba8152295\n",
      "To: /content/balltime/weights/all_weights.zip\n",
      "  0%|          | 0.00/401M [00:00<?, ?B/s]Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1__zkTmGwZo2z0EgbJvC14I_3kOpgQx3o\n",
      "From (redirected): https://drive.google.com/uc?id=1__zkTmGwZo2z0EgbJvC14I_3kOpgQx3o&confirm=t&uuid=f126d249-1b98-4fdc-88b0-336ba8152295\n",
      "To: /content/balltime/weights/all_weights.zip\n",
      "100%|██████████| 401M/401M [00:06<00:00, 58.6MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO: Successfully downloaded to /content/balltime/weights/all_weights.zip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32mINFO:ml_manager:Successfully downloaded to /content/balltime/weights/all_weights.zip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO: Extracting weights to /content/balltime/weights\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:ml_manager:Extracting weights to /content/balltime/weights\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO: ZIP file extracted and removed\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:ml_manager:ZIP file extracted and removed\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSUCCESS: Successfully extracted all 4 models\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mSUCCESS:ml_manager:Successfully extracted all 4 models\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSUCCESS: Successfully downloaded all model weights\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mSUCCESS:ml_manager:Successfully downloaded all model weights\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO: Initializing ActionDetector with model: /content/balltime/weights/action/weights/best.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:ml_manager:Initializing ActionDetector with model: /content/balltime/weights/action/weights/best.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO: Loading YOLO model from: /content/balltime/weights/action/weights/best.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:ml_manager:Loading YOLO model from: /content/balltime/weights/action/weights/best.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO: Moving YOLO model to device: cuda:0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:ml_manager:Moving YOLO model to device: cuda:0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSUCCESS: Action detection model loaded: /content/balltime/weights/action/weights/best.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mSUCCESS:ml_manager:Action detection model loaded: /content/balltime/weights/action/weights/best.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO: Initializing BallDetector with model: /content/balltime/weights/ball/weights/best.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:ml_manager:Initializing BallDetector with model: /content/balltime/weights/ball/weights/best.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO: Loading YOLO model from: /content/balltime/weights/ball/weights/best.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:ml_manager:Loading YOLO model from: /content/balltime/weights/ball/weights/best.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO: Moving YOLO model to device: cuda:0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:ml_manager:Moving YOLO model to device: cuda:0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSUCCESS: Ball segmentation model loaded: /content/balltime/weights/ball/weights/best.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mSUCCESS:ml_manager:Ball segmentation model loaded: /content/balltime/weights/ball/weights/best.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO: Initializing CourtSegmentation with model: /content/balltime/weights/court/weights/best.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:ml_manager:Initializing CourtSegmentation with model: /content/balltime/weights/court/weights/best.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO: Loading YOLO model from: /content/balltime/weights/court/weights/best.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:ml_manager:Loading YOLO model from: /content/balltime/weights/court/weights/best.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO: Moving YOLO model to device: cuda:0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:ml_manager:Moving YOLO model to device: cuda:0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSUCCESS: Court segmentation model loaded: /content/balltime/weights/court/weights/best.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mSUCCESS:ml_manager:Court segmentation model loaded: /content/balltime/weights/court/weights/best.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO: Initializing PlayerModule with model: yolo11n-pose.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:ml_manager:Initializing PlayerModule with model: yolo11n-pose.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO: Loading YOLO model from: yolo11n-pose.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:ml_manager:Loading YOLO model from: yolo11n-pose.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-pose.pt to 'yolo11n-pose.pt': 100% ━━━━━━━━━━━━ 6.0MB 107.9MB/s 0.1s\n",
      "\u001b[32mINFO: Moving YOLO model to device: cuda:0\u001b[0m\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-pose.pt to 'yolo11n-pose.pt': 100% ━━━━━━━━━━━━ 6.0MB 107.9MB/s 0.1s\n",
      "\u001b[32mINFO: Moving YOLO model to device: cuda:0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:ml_manager:Moving YOLO model to device: cuda:0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSUCCESS: Default YOLO pose estimation model loaded for player keypoint detection\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mSUCCESS:ml_manager:Default YOLO pose estimation model loaded for player keypoint detection\u001b[0m\n",
      "WARNING:root:You are using a scalar distance function. If you want to speed up the tracking process please consider using a vectorized distance function such as ['iou', 'iou_opt', 'braycurtis', 'canberra', 'chebyshev', 'cityblock', 'correlation', 'cosine', 'dice', 'euclidean', 'hamming', 'jaccard', 'jensenshannon', 'kulczynski1', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule'].\n",
      "WARNING:root:You are using a scalar distance function. If you want to speed up the tracking process please consider using a vectorized distance function such as ['iou', 'iou_opt', 'braycurtis', 'canberra', 'chebyshev', 'cityblock', 'correlation', 'cosine', 'dice', 'euclidean', 'hamming', 'jaccard', 'jensenshannon', 'kulczynski1', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSUCCESS: Tracking module initialized successfully\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mSUCCESS:ml_manager:Tracking module initialized successfully\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO: Initializing GameStatusClassifier with model: /content/balltime/weights/game_state\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:ml_manager:Initializing GameStatusClassifier with model: /content/balltime/weights/game_state\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Failed to load game state classification model: Failed to load VideoMAE model: Error(s) in loading state_dict for Linear:\n",
      "\tsize mismatch for bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([2]).\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR:ml_manager:Failed to load game state classification model: Failed to load VideoMAE model: Error(s) in loading state_dict for Linear:\n",
      "\tsize mismatch for bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([2]).\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSUCCESS: Visualization module initialized successfully\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mSUCCESS:ml_manager:Visualization module initialized successfully\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSUCCESS: All models initialized successfully!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mSUCCESS:ml_manager:All models initialized successfully!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MLManager imported & initialized\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "\n",
    "if str(MODELS_DIR) not in sys.path:\n",
    "    sys.path.append(str(MODELS_DIR))\n",
    "\n",
    "from volleyball_ml import MLManager\n",
    "\n",
    "manager = MLManager(device=\"cuda:0\")  # or \"cuda\" if you enabled GPU\n",
    "print(\"✅ MLManager imported & initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4361bf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-detect Colab and mount Google Drive for videos\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"Running on Colab. Mounting Google Drive...\")\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=False)\n",
    "    # Point to videos folder on Drive\n",
    "    DRIVE_VIDEOS_PATH = Path('/content/drive/MyDrive/videos')\n",
    "    if DRIVE_VIDEOS_PATH.exists():\n",
    "        print(f\"✅ Videos found at {DRIVE_VIDEOS_PATH}\")\n",
    "    else:\n",
    "        print(f\"⚠️  {DRIVE_VIDEOS_PATH} not found. Ensure videos are in MyDrive/videos/\")\n",
    "else:\n",
    "    print(\"Running locally. Using local balltime/videos folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7393e69",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Tuple\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class VideoDetectionTensor:\n",
    "    \"\"\"\n",
    "    Holds per-frame confidence tensor for a single video.\n",
    "    Convention: 0.0 for frames with no ball; >0.0 confidence for detected ball.\n",
    "    \"\"\"\n",
    "    video_path: Path\n",
    "    fps: float\n",
    "    frame_count: int\n",
    "    # 1D tensor of length frame_count or sampled_count (after frame skipping)\n",
    "    confidences: np.ndarray  # dtype float16/float32, shape: [N]\n",
    "    sample_rate: int = 1\n",
    "\n",
    "    def detected_indices(self, threshold: float = 0.0) -> np.ndarray:\n",
    "        return np.where(self.confidences > threshold)[0]\n",
    "\n",
    "    def as_numpy(self) -> np.ndarray:\n",
    "        return self.confidences\n",
    "\n",
    "    def save_npz(self, out_path: Path) -> None:\n",
    "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        np.savez_compressed(\n",
    "            out_path,\n",
    "            video_path=str(self.video_path),\n",
    "            fps=self.fps,\n",
    "            frame_count=self.frame_count,\n",
    "            sample_rate=self.sample_rate,\n",
    "            confidences=self.confidences,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def load_npz(in_path: Path) -> \"VideoDetectionTensor\":\n",
    "        data = np.load(in_path, allow_pickle=True)\n",
    "        return VideoDetectionTensor(\n",
    "            video_path=Path(str(data[\"video_path\"])) ,\n",
    "            fps=float(data[\"fps\"]),\n",
    "            frame_count=int(data[\"frame_count\"]),\n",
    "            sample_rate=int(data[\"sample_rate\"]),\n",
    "            confidences=data[\"confidences\"],\n",
    "        )\n",
    "\n",
    "\n",
    "class VideoObject:\n",
    "    \"\"\"\n",
    "    Represents a video and its derived detection tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, video_path: Path):\n",
    "        self.video_path = Path(video_path)\n",
    "        self.tensor: Optional[VideoDetectionTensor] = None\n",
    "\n",
    "    def attach_tensor(self, tensor: VideoDetectionTensor) -> None:\n",
    "        self.tensor = tensor\n",
    "\n",
    "    def get_tensor(self) -> VideoDetectionTensor:\n",
    "        if self.tensor is None:\n",
    "            raise ValueError(\"Tensor not computed/attached for this video.\")\n",
    "        return self.tensor\n",
    "\n",
    "\n",
    "def videos_to_objects(folder: Path) -> List[VideoObject]:\n",
    "    \"\"\"Scan a folder and create VideoObject entries for common video extensions.\"\"\"\n",
    "    exts = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}\n",
    "    folder = Path(folder)\n",
    "    if not folder.exists():\n",
    "        return []\n",
    "    return [VideoObject(p) for p in sorted(folder.iterdir()) if p.suffix.lower() in exts]\n",
    "\n",
    "\n",
    "def train_test_split_videos(\n",
    "    video_objects: List[VideoObject],\n",
    "    test_ratio: float = 0.2,\n",
    "    min_train: int = 16,\n",
    "    min_test: int = 4,\n",
    ") -> Tuple[List[VideoObject], List[VideoObject]]:\n",
    "    \"\"\"\n",
    "    Deterministic split: first N for train, last M for test.\n",
    "    Guarantees at least min_train/min_test when possible.\n",
    "    \"\"\"\n",
    "    n = len(video_objects)\n",
    "    if n == 0:\n",
    "        return [], []\n",
    "    # Compute test size by ratio, then ensure minimums\n",
    "    test_size = max(int(n * test_ratio), min_test)\n",
    "    train_size = max(n - test_size, min_train)\n",
    "    # Adjust to not exceed total\n",
    "    if train_size + test_size > n:\n",
    "        test_size = n - train_size\n",
    "        if test_size < 0:\n",
    "            test_size = 0\n",
    "    train = video_objects[:train_size]\n",
    "    test = video_objects[train_size:train_size + test_size]\n",
    "    return train, test\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Label utilities (binary per-frame CSV)\n",
    "# -----------------------------\n",
    "def _load_video_meta(video_path: Path) -> Tuple[int, float]:\n",
    "    \"\"\"Return (frame_count, fps) for the given video.\"\"\"\n",
    "    import cv2\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = float(cap.get(cv2.CAP_PROP_FPS))\n",
    "    cap.release()\n",
    "    return frame_count, fps\n",
    "\n",
    "\n",
    "def build_binary_labels_for_video(\n",
    "    video_path: Path,\n",
    "    timestamp_pairs_seconds: List[Tuple[float, float]],\n",
    "    *,\n",
    "    inclusive: bool = True,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create a binary array over frames: 1 if frame time (in seconds) falls within\n",
    "    any of the provided (start_s, end_s) pairs, else 0. Timestamps are inclusive\n",
    "    at boundaries when inclusive=True.\n",
    "\n",
    "    Args:\n",
    "        video_path: Path to the video file.\n",
    "        timestamp_pairs_seconds: List of (start_seconds, end_seconds) pairs.\n",
    "        inclusive: Include boundary frames when True.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray of shape [frame_count], dtype=np.uint8 with 0/1 values.\n",
    "    \"\"\"\n",
    "    frame_count, fps = _load_video_meta(video_path)\n",
    "    labels = np.zeros(frame_count, dtype=np.uint8)\n",
    "    # Pre-normalize intervals so start <= end\n",
    "    intervals = []\n",
    "    for s, e in timestamp_pairs_seconds:\n",
    "        if s > e:\n",
    "            s, e = e, s\n",
    "        intervals.append((max(0.0, float(s)), float(e)))\n",
    "\n",
    "    # Fill labels by interval\n",
    "    for s, e in intervals:\n",
    "        # Convert seconds to frame indices\n",
    "        if inclusive:\n",
    "            start_idx = int(np.floor(s * fps))\n",
    "            end_idx = int(np.floor(e * fps))\n",
    "        else:\n",
    "            start_idx = int(np.ceil(s * fps))\n",
    "            end_idx = int(np.floor(e * fps) - 1)\n",
    "        start_idx = max(0, start_idx)\n",
    "        end_idx = min(frame_count - 1, end_idx)\n",
    "        if end_idx >= start_idx:\n",
    "            labels[start_idx:end_idx + 1] = 1\n",
    "    return labels\n",
    "\n",
    "\n",
    "def write_video_binary_labels_row(\n",
    "    csv_path: Path,\n",
    "    video_path: Path,\n",
    "    labels: np.ndarray,\n",
    ") -> None:\n",
    "    \"\"\"Append a CSV row: [video_name, b0, b1, ..., bN].\"\"\"\n",
    "    import csv\n",
    "    csv_path = Path(csv_path)\n",
    "    csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    header_needed = not csv_path.exists()\n",
    "    with open(csv_path, \"a\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        if header_needed:\n",
    "            w.writerow([\"video\", \"labels...\"])  # simple header\n",
    "        row = [Path(video_path).name] + [int(x) for x in labels.tolist()]\n",
    "        w.writerow(row)\n",
    "\n",
    "\n",
    "def build_and_write_video_labels_csv_row(\n",
    "    csv_path: Path,\n",
    "    video_path: Path,\n",
    "    timestamp_pairs_seconds: List[Tuple[float, float]],\n",
    "    inclusive: bool = True,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate binary labels for a video based on timestamp pairs and append\n",
    "    a single row to the CSV.\n",
    "\n",
    "    Returns the labels array for further use.\n",
    "    \"\"\"\n",
    "    labels = build_binary_labels_for_video(video_path, timestamp_pairs_seconds, inclusive=inclusive)\n",
    "    write_video_binary_labels_row(csv_path, video_path, labels)\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d291ed",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using VIDEOS_DIR=/content/balltime/videos\n",
      "No video files detected in videos directory.\n",
      "Video objects created: 0\n",
      "Need at least 19 videos; found 0. Add more videos.\n"
     ]
    }
   ],
   "source": [
    "# Minimal imports only (assumes prior cells ran and installed versions)\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Determine videos directory based on environment\n",
    "if IS_COLAB:\n",
    "    VIDEOS_DIR = DRIVE_VIDEOS_PATH  # From Drive mount cell\n",
    "else:\n",
    "    # Local: use repo videos folder\n",
    "    try:\n",
    "        PROJECT_ROOT\n",
    "    except NameError:\n",
    "        PROJECT_ROOT = Path.cwd()\n",
    "    VIDEOS_DIR = (PROJECT_ROOT / \"videos\").resolve()\n",
    "\n",
    "VIDEOS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Debug: list video files found\n",
    "exts = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}\n",
    "video_files = [p for p in VIDEOS_DIR.iterdir() if p.suffix.lower() in exts]\n",
    "print(f\"Using VIDEOS_DIR={VIDEOS_DIR}\")\n",
    "print(f\"Found {len(video_files)} video files: {[p.name for p in video_files]}\" if video_files else \"No video files detected in videos directory.\")\n",
    "\n",
    "# Inference parameters\n",
    "BATCH_SIZE = 32\n",
    "SAMPLE_RATE = 2\n",
    "CONF_THRESHOLD = 0.25\n",
    "FP16 = True\n",
    "TOP_HALF_ONLY = True  # run detection on top half to save compute\n",
    "\n",
    "# Build video object list from in-notebook definitions\n",
    "video_objs = videos_to_objects(VIDEOS_DIR)\n",
    "print(f\"Video objects created: {len(video_objs)}\")\n",
    "\n",
    "# Fixed split: 14 train, 2 val, 3 test; extras go to train\n",
    "REQ_TRAIN, REQ_VAL, REQ_TEST = 14, 2, 3\n",
    "TOTAL_REQ = REQ_TRAIN + REQ_VAL + REQ_TEST\n",
    "if len(video_objs) < TOTAL_REQ:\n",
    "    print(f\"Need at least {TOTAL_REQ} videos; found {len(video_objs)}. Add more videos.\")\n",
    "    train_videos, val_videos, test_videos = [], [], []\n",
    "else:\n",
    "    train_videos = video_objs[:REQ_TRAIN]\n",
    "    val_videos = video_objs[REQ_TRAIN:REQ_TRAIN + REQ_VAL]\n",
    "    test_videos = video_objs[REQ_TRAIN + REQ_VAL:REQ_TRAIN + REQ_VAL + REQ_TEST]\n",
    "    extras = video_objs[TOTAL_REQ:]\n",
    "    if extras:\n",
    "        train_videos += extras  # put any remaining videos into train\n",
    "    print(f\"Train: {len(train_videos)} | Val: {len(val_videos)} | Test: {len(test_videos)}\")\n",
    "\n",
    "# Access the YOLO model from MLManager (initialized earlier)\n",
    "model = manager.ball_detector.yolo_module.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1210d397",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def process_video_to_tensor(video_obj: VideoObject,\n",
    "                            batch_size: int = BATCH_SIZE,\n",
    "                            sample_rate: int = SAMPLE_RATE,\n",
    "                            conf_threshold: float = CONF_THRESHOLD,\n",
    "                            fp16: bool = FP16,\n",
    "                            top_half_only: bool = TOP_HALF_ONLY) -> VideoDetectionTensor:\n",
    "    \"\"\"Run batched, optional FP16 inference with frame skipping and store confidences tensor.\n",
    "    Optionally crops frames to top half before inference to reduce pixels processed.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(str(video_obj.video_path))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = float(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    sampled_count = (total_frames + sample_rate - 1) // sample_rate\n",
    "    confidences = np.zeros(sampled_count, dtype=np.float16 if fp16 else np.float32)\n",
    "\n",
    "    frames_batch = []\n",
    "    batch_indices = []\n",
    "    out_idx = 0\n",
    "\n",
    "    pbar = tqdm(total=sampled_count, desc=f\"Processing {video_obj.video_path.name}\")\n",
    "\n",
    "    for frame_idx in range(0, total_frames, sample_rate):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "\n",
    "        if top_half_only:\n",
    "            h = frame.shape[0]\n",
    "            frame = frame[: h // 2, :, :]\n",
    "\n",
    "        frames_batch.append(frame)\n",
    "        batch_indices.append(out_idx)\n",
    "        out_idx += 1\n",
    "\n",
    "        # Run when batch is full or at end\n",
    "        at_end = (frame_idx + sample_rate >= total_frames)\n",
    "        if len(frames_batch) == batch_size or at_end:\n",
    "            # Ultralytics YOLO inference; half=True for FP16\n",
    "            results = model(frames_batch, conf=conf_threshold, verbose=False, half=fp16)\n",
    "\n",
    "            # Store confidences (0 when no detection)\n",
    "            for i, res in enumerate(results):\n",
    "                idx = batch_indices[i]\n",
    "                if hasattr(res, 'boxes') and res.boxes is not None and len(res.boxes) > 0:\n",
    "                    best = res.boxes.conf.argmax()\n",
    "                    confidences[idx] = float(res.boxes.conf[best])\n",
    "                else:\n",
    "                    confidences[idx] = 0.0\n",
    "\n",
    "            pbar.update(len(frames_batch))\n",
    "            frames_batch.clear()\n",
    "            batch_indices.clear()\n",
    "\n",
    "    cap.release()\n",
    "    pbar.close()\n",
    "\n",
    "    tensor = VideoDetectionTensor(\n",
    "        video_path=video_obj.video_path,\n",
    "        fps=fps,\n",
    "        frame_count=total_frames,\n",
    "        confidences=confidences,\n",
    "        sample_rate=sample_rate,\n",
    "    )\n",
    "    video_obj.attach_tensor(tensor)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "import csv\n",
    "CSV_PATH = PROJECT_ROOT / \"tensor_index.csv\"\n",
    "\n",
    "\n",
    "def write_video_tensor_csv(video_objs, csv_path=CSV_PATH):\n",
    "    \"\"\"Write rows: [video_path, c0, c1, ..., cN] using attached tensors.\"\"\"\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"video_path\", \"confidences...\"])  # header\n",
    "        for vo in video_objs:\n",
    "            if vo.tensor is None:\n",
    "                continue\n",
    "            row = [str(vo.video_path)] + [float(x) for x in vo.tensor.confidences]\n",
    "            w.writerow(row)\n",
    "    print(f\"Wrote CSV: {csv_path}\")\n",
    "\n",
    "\n",
    "def read_video_tensor_csv(csv_path=CSV_PATH):\n",
    "    \"\"\"Read CSV back into {video_path: np.ndarray(confidences)} mapping.\"\"\"\n",
    "    data = {}\n",
    "    with open(csv_path, \"r\", newline=\"\") as f:\n",
    "        r = csv.reader(f)\n",
    "        header = next(r, None)\n",
    "        for row in r:\n",
    "            video_path = row[0]\n",
    "            confs = np.array([float(x) for x in row[1:]], dtype=np.float32)\n",
    "            data[video_path] = confs\n",
    "    return data\n",
    "\n",
    "\n",
    "def build_all_tensors_and_write_csv():\n",
    "    \"\"\"Compute tensors for train/val/test (if enough videos) and write CSV.\"\"\"\n",
    "    if len(video_objs) < TOTAL_REQ:\n",
    "        print(f\"Add more videos to the 'videos' folder (need >= {TOTAL_REQ}).\")\n",
    "        return\n",
    "    print(\"Building tensors for training set...\")\n",
    "    for vo in train_videos:\n",
    "        _ = process_video_to_tensor(vo)\n",
    "    print(\"Building tensors for validation set...\")\n",
    "    for vo in val_videos:\n",
    "        _ = process_video_to_tensor(vo)\n",
    "    print(\"Building tensors for test set...\")\n",
    "    for vo in test_videos:\n",
    "        _ = process_video_to_tensor(vo)\n",
    "    write_video_tensor_csv(train_videos + val_videos + test_videos)\n",
    "    print(\"All tensors built and CSV written.\")\n",
    "\n",
    "\n",
    "build_all_tensors_and_write_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092a31ac",
   "metadata": {},
   "source": [
    "Now after installing the requirements/dependencies, we're going to work on using it to go through all of our data. Should I check accuracy here? I think here is where I need to build out the object/classes i need to store the results of the ball-detection model. The objects should store a pointer to the original video. not the frame. Frames should be stored in the object as some feature. the workflow should be video --> model --> object with feature 1: tensor with index 1:1 frame of confidence of ball detection. Need to see if model always outputs a "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
